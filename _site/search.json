[
  {
    "objectID": "teaching.html#course-syllabus-1",
    "href": "teaching.html#course-syllabus-1",
    "title": "Teaching",
    "section": "Course Syllabus",
    "text": "Course Syllabus"
  },
  {
    "objectID": "teaching.html#course-syllabus-2",
    "href": "teaching.html#course-syllabus-2",
    "title": "Teaching",
    "section": "Course Syllabus",
    "text": "Course Syllabus"
  },
  {
    "objectID": "posts/Machine Learning in Accounting.html",
    "href": "posts/Machine Learning in Accounting.html",
    "title": "Machine Learning in Accounting",
    "section": "",
    "text": "About this site\n\nimport matplotlib.pyplot as plt \nimport seaborn as sns\n\nimport sklearn\n\n\nimport os"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I am an Assistant Professor in School of Accountancy in College of Business and Analytics in Southern Illinois University Carbondale. My teaching and research interests lie in the intersection between Accounting and Data Science.\n\nEducation\n\nDBA, Major: Computer Information Systems; Minor: Accounting, Louisiana Tech University\nMBA, Major: Accountancy, Eastern Illinois University\nMBA, Major: Accounting & Information Systems, University of Dhaka\nBBA, Major: Accounting & Information Systems, University of Dhaka\n\n\n\nProfessional Certification\n\nCPA, State of Illinois\nCMA, Bangladesh\n\n\n\nResearch Interests\n\nData Breaches\nCybersecurity\nNetwork Centrality of Executives\nInternational Accounting\nAudit Efficiency and Timeliness\n\n\n\nTeaching Interests\n\nAuditing & Assurance Service\nAccounting Information Systems\nData Analytics\nMachine Learning\n\n\n\nHobbies\nI enjoy outdoor activities a lot, specially fishing and hiking in Southern Illinois. I like the outdoors of Southern Illinois."
  },
  {
    "objectID": "blogs.html",
    "href": "blogs.html",
    "title": "Blogs",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nUsing Arrow & DuckDB to Handle Large Data\n\n\n\n\n\nHow to Use Arrow & DuckDB in RStudio\n\n\n\n\n\nMay 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nArtificial Intelligence in Accounting\n\n\n\n\n\nHow is Artificial Intelligence affecting Accounting?\n\n\n\n\n\nMar 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nSome Good Books on Statistics, Data Visualizations, and Modeling\n\n\n\n\n\nBooks on Statistics, Visualizations, and Modeling\n\n\n\n\n\nMay 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nData Manipulation Using Tidyverse\n\n\n\n\n\nHow can Tidyverse be Used for Data Manipulation?\n\n\n\n\n\nMar 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHow Hackers Stole $81 Million from Bangaldesh Central Bank\n\n\n\n\n\nHow does Hacking Work?\n\n\n\n\n\nMar 31, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nMachine Learning in Accounting\n\n\n\n\n\nHow does Machine Learning affect Accounting?\n\n\n\n\n\nFeb 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nSpreading of Misinformation\n\n\n\n\n\nHow does Misinformation Spread?\n\n\n\n\n\nJan 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nPolars- A Python Library for Data Analytics\n\n\n\n\n\nPolars - An Alternative to Pandas \n\n\n\n\n\nApr 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nEmpirical Research in Accounting & Finance\n\n\n\n\n\nFree Books for Empirical Research in Accounting & Finance\n\n\n\n\n\nApr 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nExtracting Data from WRDS and Saving the Data into Local PostgreSQL Database\n\n\n\n\n\nHow to Extract Data from WRDS Database and Save the Data in Your Local Database Using RStudio and PostgreSQL\n\n\n\n\n\nMay 12, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Artifical Intelligence in Accounting.html",
    "href": "posts/Artifical Intelligence in Accounting.html",
    "title": "Artificial Intelligence in Accounting",
    "section": "",
    "text": "In today’s rapidly changing world, artificial intelligence (AI) is not just a buzzword but a beacon of transformation across various sectors and industries. Accounting firms, traditionally perceived as bastions of meticulousness and conservatism, are now at the forefront of this revolution, harnessing AI to redefine their operations, service offerings, and client interactions. The integration of AI in accounting is not merely an enhancement; it’s a radical reinvention that is shaping the future of the industry. It’s a seismic shift that is redefining the realm of numbers and finance. Beyond task automation, this is about opening doors to new possibilities, transforming the way accountants work, and reshaping the industry’s future. To get more insights about the role of AI in Accounting, please read the full article here."
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Project",
    "section": "",
    "text": "CEO Network Centrality & Audit Timeliness\nThe study examines the association between CEO’s network connections and audit timeliness. Based on extant research, we hypothesize that well-connected CEOs are associated with reduced audit lag. Using a sample of over 2000 firms for the period 2004 to 2017, we find that, ceteris paribus, firms with well-connected CEOs are associated with reduced audit lag. We also find firms led by more connected CEOs have better financial reporting quality and pay higher auditing fees for increased audit efforts. In addition, well-connected CEO firms release 10-K reports in a timelier manner. These findings suggest that improved information environment around well-connected CEOs lead to the timely dissemination of high-quality financial information to market participants.\n\n\nAudit Committee Social Capital & Audit Fees\nThe study examines the effect of audit committees connectedness, measured using network centrality from social network theory, on audit fees. We also test the effect of the same on audit quality and audit timeliness. We find that network centrality measures of audit committees are positively and significantly associated with audit fees. Moreover, we document that audit committees connectedness is associated with better financial reporting quality and audit timeliness, which might explain the increase in audit fees. We conduct several robustness tests and document the same results. Additional analysis indicates that the results are driven by the overall centrality of the audit committee and not by the centrality of committee chairs, committee financial experts, or members of the committee. Our results also hold true for both pre and post SOX period and after controlling for CEO and CFO network centrality measures. Overall, the findings suggest that connected audit committees are associated with higher audit fees because they demand better audit quality and timely dissemination of information.\n\n\nReaction of Rival Firms to the Information Security Breach of Focal Firms: Evidence from Market Activity and Information Asymmetry\nUsing competitive dynamics theory and theory of information transfer, this research examines whether there is a spillover effect from information security breaches of breached firms to those firms’ rivals. The spillover effects on rivals might be - the same as (contagion effect) or opposite (competitive effect) to - those of breached firms. The market reaction of spillover effects is measured from market activity and information asymmetry. The results suggest that the market of rival firms reacts to the breached firms’ experience of data breaches. The overall effects of data breaches on rival firms are the opposite to those to focal firms (competitive effect), although in some cases rival firms also experience negative reactions (contagion effect) in markets. Specifically, the results suggest that the characteristics of data breach types and previous data breach histories of focal firms have negative implications (contagion effect) for rivals. However, strong information technology governance of rivals plays a shielding role in mitigating those negative effects."
  },
  {
    "objectID": "books.html",
    "href": "books.html",
    "title": "Books",
    "section": "",
    "text": "Data Analytics in Accounting\nData analytics is important for accounting profession because data gathering and analytics technologies have the potential to fundamentally change accounting and auditing task processes (Schneider et al. 2015). Scholars note that the emergence of data analytics will significantly change the infer/predict/assure (e.g., insight/foresight/oversight) tasks performed by accountants and auditors. Big data and analytics have increasingly important implications for accounting and will provide the means to improve managerial accounting, financial accounting, and financial reporting practices (Warren Jr, Moffitt, and Byrnes 2015). It is further suggested that big data offers an unprecedented potential for diverse, voluminous datasets and sophisticated analyses. Research indicates that big data has great potential to produce better forecast estimates, going concern calculations, fraud, and other variables that are of concern to both internal and external auditors (Alles 2015). Moreover, auditors might reduce audit costs and enhance profitability and effectiveness by means of big data or data analytics. Sixty-six percent of internal audit departments currently utilize some form of data analytics as part of the audit process (Protiviti 2017).\nLink of the Book Data Analytics in Accounting\n\n\nMachine Learning in Business\nThe book is under development."
  },
  {
    "objectID": "posts_teaching/acct460_auditing.html",
    "href": "posts_teaching/acct460_auditing.html",
    "title": "Auditing & Assurance Services",
    "section": "",
    "text": "Introduction\n\nimport matplotlib.pyplot as plt \nimport seaborn as sns\n\nimport sklearn\n\n\nimport os\n\n\n\nCourse Syllabus"
  },
  {
    "objectID": "posts/Misinformation.html",
    "href": "posts/Misinformation.html",
    "title": "Spreading of Misinformation",
    "section": "",
    "text": "Just 12 people are responsible for the majority of COVID-19 conspiracy theories online, study finds. JFK’s anti-vaxxer nephew is one of the ’disinformation dozen."
  },
  {
    "objectID": "posts_teaching/acct360_ais.html",
    "href": "posts_teaching/acct360_ais.html",
    "title": "Accounting Information Systems",
    "section": "",
    "text": "Introduction\n\nimport matplotlib.pyplot as plt \nimport seaborn as sns\n\nimport sklearn\n\n\nimport os\n\n\n\nCourse Syllabus"
  },
  {
    "objectID": "posts_teaching/bsan405_ml.html",
    "href": "posts_teaching/bsan405_ml.html",
    "title": "Machine Learning in Business",
    "section": "",
    "text": "Introduction\n\nimport matplotlib.pyplot as plt \nimport seaborn as sns\n\nimport sklearn\n\n\nimport os\n\n\n\nCourse Syllabus"
  },
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "Teaching",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nAccounting Information Systems\n\n\n\n\n\nHow does the AIS Work?\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nAuditing & Assurance Services\n\n\n\n\n\nHow do the Auditors Work?\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nMachine Learning in Business\n\n\n\n\n\nHow does Machine Learning Work in Business?\n\n\n\n\n \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/datamanipulationtyidyverse.html",
    "href": "posts/datamanipulationtyidyverse.html",
    "title": "Data Manipulation Using Tidyverse",
    "section": "",
    "text": "Importing Necessary Packages\n\nlibrary(tidyverse)\nlibrary (janitor)\nlibrary (lubridate)\n\n\n\nImporting Datasets\n\niris %&gt;% \n  as_tibble() %&gt;% \n  glimpse()\n\nRows: 150\nColumns: 5\n$ Sepal.Length &lt;dbl&gt; 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.…\n$ Sepal.Width  &lt;dbl&gt; 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.…\n$ Petal.Length &lt;dbl&gt; 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.…\n$ Petal.Width  &lt;dbl&gt; 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.…\n$ Species      &lt;fct&gt; setosa, setosa, setosa, setosa, setosa, setosa, setosa, s…"
  },
  {
    "objectID": "posts/Research_in_accountng_finance.html",
    "href": "posts/Research_in_accountng_finance.html",
    "title": "Empirical Research in Accounting & Finance",
    "section": "",
    "text": "Some Good Books to Learn Research Methodologies in Accounting & Finance -\n\nEmpirical Research in Accounting: Tools and Methods\nTidy Finance with R\nTidy Finance with Python"
  },
  {
    "objectID": "posts/Polars-python-data-library.html",
    "href": "posts/Polars-python-data-library.html",
    "title": "Polars- A Python Library for Data Analytics",
    "section": "",
    "text": "polars library - An alternative to pandas library in Python.\n\nPolars Cookbook"
  },
  {
    "objectID": "posts/WRDS_to_local_POSTGRESQL.html",
    "href": "posts/WRDS_to_local_POSTGRESQL.html",
    "title": "Extracting Data from WRDS and Saving the Data into Local PostgreSQL Database",
    "section": "",
    "text": "WRDS is a widely used database by Accounting & Finance researchers and professionals all over the world. Using RStudio to pull data from WRDS is a convenient and effective data management approach. Further, the collected data from WRDS can easily be saved in a local database in your computer. The local database can be created by using PostgreSQL.\nBefore you start the process, please import the following libraries in your RStudio -\n\nlibrary(tidyverse)\nlibrary(DBI)\nlibrary(RPostgres)"
  },
  {
    "objectID": "posts/WRDS_to_local_POSTGRESQL.html#how-to-set-up-pgpass.conf-file-in-your-machine",
    "href": "posts/WRDS_to_local_POSTGRESQL.html#how-to-set-up-pgpass.conf-file-in-your-machine",
    "title": "Extracting Data from WRDS and Saving the Data into Local PostgreSQL Database",
    "section": "3.1 How to Set Up Pgpass.conf file in Your Machine",
    "text": "3.1 How to Set Up Pgpass.conf file in Your Machine\nOn Windows, the Postgres Password file is named pgpass.conf, and is located in your %APPDATA% directory. It is a hidden directory. It can be accessed by typing %APPDATA% in your Windows Explorer Address bar. Within that directory, create a new folder called ‘postgreSQL’ and then open it. Finally create a new file within this directory called ‘pgpass.conf’ using a plaintext editors such as NotePad++. Please note that NotePad (without ++), WordPad, and MS Word are not plaintext editors. Please do not use them for this step. The full path to the file should therefore be -\n%APPDATA%\\postgresql\\pgpass.conf\nPlease note that %APPDATA% may expand to something similar to this -\nC:\\Users\\USERNAME\\AppData\\Roaming\\postgresql\\pgpass.conf\nPlace the following line into the new pgpass.conf file and save it -\nwrds-pgdata.wharton.upenn.edu:9737:wrds:wrds_username:wrds_password\nwhere ‘wrds_username’ is your WRDS username and ‘wrds_password’ is your WRDS password.\nPlease note that your password contains either a colon (:) or a backslash (\\), you will need to escape those characters with a backslash:\\\nBefore you go to the next step. Please restart the R Session.\n\nRun the following line of code to get your RStudio connected to WRDS -\n\n\n######################################################\n# Connecting to WRDS Database\n#######################################################\npg &lt;- dbConnect(RPostgres::Postgres(), bigint = \"integer\")"
  },
  {
    "objectID": "posts/Arrow_DuckDB_Large_data.html",
    "href": "posts/Arrow_DuckDB_Large_data.html",
    "title": "Using Arrow & DuckDB to Handle Large Data",
    "section": "",
    "text": "Many times, we deal with large datasets such that the memory (e.g., RAM) of the machine is not enough to load or analyze the data. In such circumstances, using a database like PostgreSQL comes very handy (One can go over here to learn how to set up a PostgreSQL server). However, using a database requires knowledge of setting up database server and SQL and many people are not familiar with those kinds of knowledge. In such circumstance, using Arrow and DuckDB could be very much helpful to derive the benefits of a database."
  },
  {
    "objectID": "posts/Arrow_DuckDB_Large_data.html#loading-necessary-r-packages",
    "href": "posts/Arrow_DuckDB_Large_data.html#loading-necessary-r-packages",
    "title": "Using Arrow & DuckDB to Handle Large Data",
    "section": "4.1 Loading Necessary R Packages",
    "text": "4.1 Loading Necessary R Packages\n\n# Loading or installing necessary packages \n#install.packages('arrow')\nlibrary(arrow)\n#install.packages('duckdb')\nlibrary(duckdb)\nlibrary(DBI)\nlibrary(dbplyr)\nlibrary(fs)\nlibrary(tidyverse)"
  },
  {
    "objectID": "posts/Arrow_DuckDB_Large_data.html#covering-the-big-data-files-into-arrow-object",
    "href": "posts/Arrow_DuckDB_Large_data.html#covering-the-big-data-files-into-arrow-object",
    "title": "Using Arrow & DuckDB to Handle Large Data",
    "section": "4.2 Covering the Big Data Files into Arrow Object",
    "text": "4.2 Covering the Big Data Files into Arrow Object\n\n#####################################################\n# Arrow Object \n######################################################\ndf_arrow = arrow::open_dataset(\"path_to_the_file/name_of_the_file.csv\",\n                               format = 'csv',\n                               col_types = schema(year = as.numeric())\n                               )\n\ndf_arrow %&gt;% object.size()\n\ndf_arrow %&gt;% glimpse()"
  },
  {
    "objectID": "posts/Arrow_DuckDB_Large_data.html#sending-the-arrow-object-to-duckdb-database",
    "href": "posts/Arrow_DuckDB_Large_data.html#sending-the-arrow-object-to-duckdb-database",
    "title": "Using Arrow & DuckDB to Handle Large Data",
    "section": "4.3 Sending the Arrow Object to DuckDB Database",
    "text": "4.3 Sending the Arrow Object to DuckDB Database\n\n#####################################################\n# Using duckdb with arrow\n#####################################################\n\n# Create Directory \nduckdb_dir &lt;- path(here::here('DATA'), \"duckdb_df\")\nif (!dir.exists(duckdb_dir)) {\n  dir.create(duckdb_dir)\n}\n\n# Create Connection on DuckDB\ncon_duckdb &lt;- dbConnect(\n  drv = duckdb(),\n  dbdir = path(duckdb_dir, \"duckdb.ddb\")\n)\n\n# Sending Arrow Object in DuckDB Database\ncon_duckdb %&gt;% \n  dbWriteTable(\"name_of_the_table_in_duckdb\", collect(df_arrow), overwrite = TRUE)\n\n## TO see all schemas in the Connection\nDBI::dbListObjects(con_duckdb)"
  },
  {
    "objectID": "posts/Arrow_DuckDB_Large_data.html#manipulating-extracting-data-from-duckdb-database",
    "href": "posts/Arrow_DuckDB_Large_data.html#manipulating-extracting-data-from-duckdb-database",
    "title": "Using Arrow & DuckDB to Handle Large Data",
    "section": "4.4 Manipulating (Extracting) Data from DuckDB Database",
    "text": "4.4 Manipulating (Extracting) Data from DuckDB Database\n\ndf_duckdb = con_duckdb %&gt;% \n  tbl(\"name_of_the_table_in_duckdb\")\n\ndf_duckdb %&gt;% \n  glimpse()\n\ndf_duckdb %&gt;% \n  count() %&gt;% \n  pull() # 30,623,729 Observations \n\n\n\ndf_duckdb %&gt;% \n  select(year, cusip, ticker) %&gt;% \n  filter(year %in% 2005:2022) %&gt;% \n  filter(ticker == 'CBA') %&gt;% \n  collect()"
  },
  {
    "objectID": "posts/Arrow_DuckDB_Large_data.html#converting-the-big-data-files-into-arrow-object",
    "href": "posts/Arrow_DuckDB_Large_data.html#converting-the-big-data-files-into-arrow-object",
    "title": "Using Arrow & DuckDB to Handle Large Data",
    "section": "4.2 Converting the Big Data Files into Arrow Object",
    "text": "4.2 Converting the Big Data Files into Arrow Object\n\n#####################################################\n# Arrow Object \n######################################################\ndf_arrow = arrow::open_dataset(\"path_to_the_file/name_of_the_file.csv\",\n                               format = 'csv',\n                               col_types = schema(year = as.numeric())\n                               )\n\ndf_arrow %&gt;% object.size()\n\ndf_arrow %&gt;% glimpse()"
  },
  {
    "objectID": "posts/books-statistics-visualization.html",
    "href": "posts/books-statistics-visualization.html",
    "title": "Some Good Books on Statistics, Data Visualizations, and Modeling",
    "section": "",
    "text": "Some Good Books to Learn Statistics, Data Visualizations, and Modeling -\n\nIntroduction to Modern Statistics\nFundamentals of Data Visualization\nTidy Modeling with R\nPython for Data Science"
  }
]